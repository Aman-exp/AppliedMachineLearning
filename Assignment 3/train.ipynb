{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, precision_score, recall_score, roc_auc_score\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the processed training data\n",
    "train_data = pd.read_csv('processed_data/train.csv', sep='\\t')\n",
    "val_data = pd.read_csv('processed_data/validation.csv', sep='\\t')\n",
    "\n",
    "# Split features and target\n",
    "X_train = train_data['preprocessed_message']\n",
    "X_train = X_train.fillna('')\n",
    "y_train = train_data['label']\n",
    "\n",
    "X_val = val_data['preprocessed_message']\n",
    "X_val = X_val.fillna('')\n",
    "y_val = val_data['label']\n",
    "\n",
    "# Convert text to TF-IDF features\n",
    "tfidf = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_val_tfidf = tfidf.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize classifiers\n",
    "nb_classifier = MultinomialNB()\n",
    "svm_classifier = LinearSVC(random_state=42)\n",
    "rf_classifier = RandomForestClassifier(random_state=42, n_estimators=100)\n",
    "\n",
    "# Training the classifiers\n",
    "nb_classifier.fit(X_train_tfidf, y_train)\n",
    "svm_classifier.fit(X_train_tfidf, y_train)\n",
    "rf_classifier.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predicting on validation data\n",
    "nb_pred = nb_classifier.predict(X_val_tfidf)\n",
    "svm_pred = svm_classifier.predict(X_val_tfidf)\n",
    "rf_pred = rf_classifier.predict(X_val_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate specificity\n",
    "def specificity(y_true, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    return tn / (tn + fp)\n",
    "\n",
    "# List of classifiers and their predictions\n",
    "classifiers = ['Naive Bayes', 'Linear SVM', 'Random Forest']\n",
    "predictions = [nb_pred, svm_pred, rf_pred]\n",
    "\n",
    "# Printing model performance metrics\n",
    "print(\"Model Performance Metrics:\\n\")\n",
    "print(\"Classifier\\t\\t\\tAccuracy\\tF1 Score\\tRecall\\t\\tPrecision\\tSpecificity\\tAUC\")\n",
    "print(\"-\" * 120)\n",
    "\n",
    "# Loop through each classifier and its predictions to print evaluation metrics\n",
    "for clf, pred in zip(classifiers, predictions):\n",
    "    acc = accuracy_score(y_val, pred)\n",
    "    f1 = f1_score(y_val, pred)\n",
    "    r = recall_score(y_val, pred)\n",
    "    p = precision_score(y_val, pred)\n",
    "    auc = roc_auc_score(y_val, pred)\n",
    "    s = specificity(y_val, pred)\n",
    "    print(f\"{clf:<20}\\t\\t{acc:.4f}\\t\\t{f1:.4f}\\t\\t{r:.4f}\\t\\t{p:.4f}\\t\\t{s:.4f}\\t\\t{auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the processed test data\n",
    "test_data = pd.read_csv('processed_data/test.csv', sep='\\t')\n",
    "\n",
    "# Split features and target\n",
    "X_test = test_data['preprocessed_message']\n",
    "X_test = X_test.fillna('')\n",
    "y_test = test_data['label']\n",
    "\n",
    "X_test_tfidf = tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on test data\n",
    "nb_pred = nb_classifier.predict(X_test_tfidf)\n",
    "svm_pred = svm_classifier.predict(X_test_tfidf)\n",
    "rf_pred = rf_classifier.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = ['Naive Bayes', 'Linear SVM', 'Random Forest']\n",
    "predictions = [nb_pred, svm_pred, rf_pred]\n",
    "\n",
    "print(\"Model Performance Metrics:\\n\")\n",
    "print(\"Classifier\\t\\t\\tAccuracy\\tF1 Score\\tRecall\\t\\tPrecision\\tSpecificity\\tAUC\")\n",
    "print(\"-\" * 120)\n",
    "\n",
    "for clf, pred in zip(classifiers, predictions):\n",
    "    acc = accuracy_score(y_test, pred)\n",
    "    f1 = f1_score(y_test, pred)\n",
    "    r = recall_score(y_test, pred)\n",
    "    p = precision_score(y_test, pred)\n",
    "    auc = roc_auc_score(y_test, pred)\n",
    "    s = specificity(y_test, pred)\n",
    "    print(f\"{clf:<20}\\t\\t{acc:.4f}\\t\\t{f1:.4f}\\t\\t{r:.4f}\\t\\t{p:.4f}\\t\\t{s:.4f}\\t\\t{auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save best model (using the Random Forest classifier instead of Logistic Regression)\n",
    "best_model = rf_classifier\n",
    "joblib.dump(best_model, 'best_model.pkl')\n",
    "joblib.dump(tfidf, 'vectorizer.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
